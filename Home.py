"""
ã—ã®ã†ãŸã‚¿ã‚¤ãƒ  - ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸

VTuberã€Œå¹½éŸ³ã—ã®ã€ã•ã‚“ã®é…ä¿¡ã§æ­Œå”±ã•ã‚ŒãŸæ¥½æ›²ã‚’æ¤œç´¢ãƒ»é–²è¦§ã§ãã‚‹
éå…¬å¼ãƒ•ã‚¡ãƒ³ã‚µã‚¤ãƒˆã®ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã§ã™ã€‚

ä¸»ãªæ©Ÿèƒ½:
- æ¥½æ›²ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨è¡¨ç¤º
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆæ›²åã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã€é…ä¿¡ã‚¿ã‚¤ãƒˆãƒ«ï¼‰
- YouTubeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒªãƒ³ã‚¯ç”Ÿæˆ
- æ®µéšçš„è¡¨ç¤ºï¼ˆ25ä»¶ãšã¤ï¼‰
- æ›²ç›®ç•ªå·ã®è‡ªå‹•ç”Ÿæˆ

ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:
- data/M_YT_LIVE.TSV: é…ä¿¡æƒ…å ±
- data/M_YT_LIVE_TIMESTAMP.TSV: æ¥½æ›²ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æƒ…å ±
"""

import streamlit as st
import pandas as pd
from PIL import Image
from footer import display_footer  # â˜…ã“ã“ã‚’è¿½åŠ â˜…
from src.config import setup_logging

# ãƒ­ã‚®ãƒ³ã‚°ã®åˆæœŸåŒ–ï¼ˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«ä¸€åº¦ã ã‘å®Ÿè¡Œï¼‰
if "logging_initialized" not in st.session_state:
    setup_logging()
    st.session_state.logging_initialized = True

# ãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚¿ãƒ–åã‚’ã€Œã—ã®ã†ãŸã‚¿ã‚¤ãƒ ã€ã«è¨­å®šã—ã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’åºƒã‚ã«è¨­å®š
st.set_page_config(
    page_title="ã—ã®ã†ãŸã‚¿ã‚¤ãƒ ",
    page_icon="ğŸ‘»",
    layout="wide",
)

# --- ã‚«ã‚¹ã‚¿ãƒ CSSã®é©ç”¨ ---
try:
    with open("style.css", encoding="utf-8") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
except FileNotFoundError:
    st.error("ã‚¨ãƒ©ãƒ¼: style.css ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.info("`style.css` ãŒã‚¢ãƒ—ãƒªã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
except Exception as e:
    st.error(f"ã‚¨ãƒ©ãƒ¼: style.css ã®èª­ã¿è¾¼ã¿ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
# --- ã‚«ã‚¹ã‚¿ãƒ CSSã®é©ç”¨ã“ã“ã¾ã§ ---

st.title("ã—ã®ã†ãŸã‚¿ã‚¤ãƒ ğŸ‘»ğŸ«§")

st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€ŒSong List betaã€ã‚’é¸æŠã—ã¦ã€æ¥½æ›²ãƒªã‚¹ãƒˆã‚’ã”è¦§ãã ã•ã„ã€‚")

# --- æ¦‚è¦æ¬„ã®è¿½åŠ  ---
st.markdown(
    """
    ã“ã¡ã‚‰ã¯VTuberã€Œ[å¹½éŸ³ã—ã®](https://www.774.ai/talent/shino-kasukane)ã€ã•ã‚“ã®é…ä¿¡ã§æ­Œã‚ã‚ŒãŸæ¥½æ›²ã‚’ã¾ã¨ã‚ãŸéå…¬å¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã™ã€‚
    æ›²åã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã€ãƒ©ã‚¤ãƒ–é…ä¿¡ã‚¿ã‚¤ãƒˆãƒ«ã§æ¤œç´¢ã§ãã¾ã™ã€‚YouTubeãƒªãƒ³ã‚¯ã‹ã‚‰è©²å½“ã®æ­Œå”±ç®‡æ‰€ã«ç›´æ¥é£›ã¹ã¾ã™ã€‚
    """
)
st.markdown("---")
# --- æ¦‚è¦æ¬„ã®è¿½åŠ ã“ã“ã¾ã§ ---

# --- TSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ ---
lives_file_path = "data/M_YT_LIVE.TSV"
songs_file_path = "data/M_YT_LIVE_TIMESTAMP.TSV"


# --- æ™‚é–“æ–‡å­—åˆ—ã‚’ç§’æ•°ã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def convert_timestamp_to_seconds(timestamp_str):
    """
    ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ–‡å­—åˆ—ã‚’ç§’æ•°ã«å¤‰æ›ã™ã‚‹
    
    YouTubeã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURLç”Ÿæˆã®ãŸã‚ã«ã€
    HH:MM:SSå½¢å¼ã¾ãŸã¯MM:SSå½¢å¼ã®æ™‚é–“æ–‡å­—åˆ—ã‚’ç§’æ•°ã«å¤‰æ›ã—ã¾ã™ã€‚
    
    Args:
        timestamp_str (str): ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ–‡å­—åˆ—
            - HH:MM:SSå½¢å¼ï¼ˆä¾‹: "1:23:45"ï¼‰
            - MM:SSå½¢å¼ï¼ˆä¾‹: "12:34"ï¼‰
    
    Returns:
        int: å¤‰æ›ã•ã‚ŒãŸç§’æ•°ã€‚å¤‰æ›ã«å¤±æ•—ã—ãŸå ´åˆã¯None
            - HH:MM:SSå½¢å¼ã®å ´åˆ: æ™‚é–“*3600 + åˆ†*60 + ç§’
            - MM:SSå½¢å¼ã®å ´åˆ: åˆ†*60 + ç§’
    
    Examples:
        >>> convert_timestamp_to_seconds("1:23:45")
        5025
        >>> convert_timestamp_to_seconds("12:34")
        754
        >>> convert_timestamp_to_seconds(None)
        None
    
    Notes:
        - å…¥åŠ›ãŒNoneã¾ãŸã¯æ–‡å­—åˆ—ã§ãªã„å ´åˆã¯Noneã‚’è¿”ã™
        - ã‚³ãƒ­ãƒ³åŒºåˆ‡ã‚ŠãŒ3ã¤ã§ã‚‚2ã¤ã§ã‚‚ãªã„å ´åˆã¯Noneã‚’è¿”ã™
    """
    if pd.isna(timestamp_str) or not isinstance(timestamp_str, str):
        return None

    parts = list(map(int, timestamp_str.split(":")))

    if len(parts) == 3:
        # HH:MM:SSå½¢å¼
        return parts[0] * 3600 + parts[1] * 60 + parts[2]
    elif len(parts) == 2:
        # MM:SSå½¢å¼
        return parts[0] * 60 + parts[1]
    else:
        return None


# --- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
# TSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é…ä¿¡æƒ…å ±ã¨æ¥½æ›²æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã‚„èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆã«
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹
df_lives = None
df_songs = None

# é…ä¿¡æƒ…å ±ï¼ˆM_YT_LIVE.TSVï¼‰ã®èª­ã¿è¾¼ã¿
# ã‚«ãƒ©ãƒ : ID, é…ä¿¡æ—¥, ã‚¿ã‚¤ãƒˆãƒ«, URL
try:
    df_lives = pd.read_csv(lives_file_path, delimiter="\t")
except FileNotFoundError:
    st.error(f'ã‚¨ãƒ©ãƒ¼: é…ä¿¡æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ« "{lives_file_path}" ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚')
    st.info(f"`{lives_file_path}` ãŒã‚¢ãƒ—ãƒªã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
except Exception as e:
    st.error(
        f'é…ä¿¡æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ« "{lives_file_path}" ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}'
    )

# æ¥½æ›²ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æƒ…å ±ï¼ˆM_YT_LIVE_TIMESTAMP.TSVï¼‰ã®èª­ã¿è¾¼ã¿
# ã‚«ãƒ©ãƒ : ID, LIVE_ID, æ›²å, ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ, ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
try:
    df_songs = pd.read_csv(songs_file_path, delimiter="\t")
except FileNotFoundError:
    st.error(f'ã‚¨ãƒ©ãƒ¼: æ¥½æ›²æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ« "{songs_file_path}" ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚')
    st.info(f"`{songs_file_path}` ãŒã‚¢ãƒ—ãƒªã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
except Exception as e:
    st.error(
        f'æ¥½æ›²æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ« "{songs_file_path}" ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}'
    )


# --- ãƒ‡ãƒ¼ã‚¿ã®çµåˆã¨è¡¨ç¤º ---
if df_lives is not None and df_songs is not None:
    # ===== ãƒ‡ãƒ¼ã‚¿çµåˆå‡¦ç† =====
    # é…ä¿¡æƒ…å ±ï¼ˆdf_livesï¼‰ã¨æ¥½æ›²æƒ…å ±ï¼ˆdf_songsï¼‰ã‚’LIVE_IDã‚’ã‚­ãƒ¼ã¨ã—ã¦çµåˆ
    # å·¦çµåˆï¼ˆleft joinï¼‰ã«ã‚ˆã‚Šã€æ¥½æ›²ãƒ‡ãƒ¼ã‚¿ã‚’åŸºæº–ã¨ã—ã¦é…ä¿¡æƒ…å ±ã‚’ç´ä»˜ã‘ã‚‹
    # ã“ã‚Œã«ã‚ˆã‚Šã€å„æ¥½æ›²ãŒã©ã®é…ä¿¡ã§æ­Œã‚ã‚ŒãŸã‹ã‚’ç‰¹å®šã§ãã‚‹
    df_merged = pd.merge(
        df_songs,
        df_lives[["ID", "é…ä¿¡æ—¥", "ã‚¿ã‚¤ãƒˆãƒ«", "URL"]],
        left_on="LIVE_ID",  # æ¥½æ›²ãƒ‡ãƒ¼ã‚¿ã®LIVE_IDã‚«ãƒ©ãƒ 
        right_on="ID",      # é…ä¿¡ãƒ‡ãƒ¼ã‚¿ã®IDã‚«ãƒ©ãƒ 
        how="left",         # å·¦çµåˆ: æ¥½æ›²ãƒ‡ãƒ¼ã‚¿ã‚’åŸºæº–ã¨ã™ã‚‹
        suffixes=("_song", "_live"),  # é‡è¤‡ã™ã‚‹åˆ—åã«æ¥å°¾è¾ã‚’ä»˜ä¸
    )

    # çµåˆã«ä½¿ç”¨ã—ãŸãŒä¸è¦ã¨ãªã£ãŸé…ä¿¡å´ã®IDåˆ—ï¼ˆID_liveï¼‰ã‚’å‰Šé™¤
    df_merged = df_merged.drop(columns=["ID_live"])

    # åˆ—åã‚’åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªåã«å¤‰æ›´
    df_merged = df_merged.rename(
        columns={
            "ID_song": "æ¥½æ›²ID",
            "é…ä¿¡æ—¥": "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_original",  # å…ƒã®é…ä¿¡æ—¥ãƒ‡ãƒ¼ã‚¿ï¼ˆUNIXãƒŸãƒªç§’ã¾ãŸã¯YYYY/MM/DDå½¢å¼ï¼‰
            "ã‚¿ã‚¤ãƒˆãƒ«": "ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒˆãƒ«",
            "URL": "å…ƒãƒ©ã‚¤ãƒ–URL",
        }
    )
    
    # è¡¨ç¤ºç”¨ã®ã€Œãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥ã€åˆ—ã‚’ä½œæˆï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼‰
    df_merged["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥"] = df_merged["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_original"]

    # ===== ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å¤‰æ›å‡¦ç† =====
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ–‡å­—åˆ—ï¼ˆHH:MM:SSã¾ãŸã¯MM:SSå½¢å¼ï¼‰ã‚’ç§’æ•°ã«å¤‰æ›
    # YouTubeã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURLç”Ÿæˆã«ä½¿ç”¨
    df_merged["ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—_ç§’"] = df_merged["ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—"].apply(
        convert_timestamp_to_seconds
    )

    # ===== æ—¥ä»˜å¤‰æ›ã¨ã‚½ãƒ¼ãƒˆå‡¦ç† =====
    # ã‚½ãƒ¼ãƒˆç”¨ã«é…ä¿¡æ—¥ã‚’æ—¥ä»˜å‹ï¼ˆdatetimeï¼‰ã«å¤‰æ›
    # ã¾ãšUNIXãƒŸãƒªç§’ã¨ã—ã¦å¤‰æ›ã‚’è©¦ã¿ã‚‹
    df_merged["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable"] = pd.to_datetime(
        df_merged["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_original"], unit="ms", errors="coerce"
    )

    # UNIXãƒŸãƒªç§’ã§å¤‰æ›ã§ããªã‹ã£ãŸè¡Œï¼ˆNaTï¼‰ã«å¯¾ã—ã¦ã€YYYY/MM/DDå½¢å¼ã¨ã—ã¦å†å¤‰æ›
    mask_nat_sortable = df_merged["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable"].isna()
    if mask_nat_sortable.any():
        try:
            df_merged.loc[mask_nat_sortable, "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable"] = pd.to_datetime(
                df_merged.loc[mask_nat_sortable, "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_original"],
                errors="coerce",
            )
        except Exception as e:
            st.warning(f"ã‚½ãƒ¼ãƒˆç”¨ã®ã€Œãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥ã€å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.warning(
                "æ—¥ä»˜ã®å½¢å¼ãŒè¤‡é›‘ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚TSVãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ã€Œé…ä¿¡æ—¥ã€ã‚«ãƒ©ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            )

    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚½ãƒ¼ãƒˆ: é…ä¿¡æ—¥é™é †ï¼ˆæ–°ã—ã„é †ï¼‰â†’ LIVE_IDæ˜‡é † â†’ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ˜‡é †
    # ã“ã‚Œã«ã‚ˆã‚Šã€æœ€æ–°ã®é…ä¿¡ãŒä¸Šã«è¡¨ç¤ºã•ã‚Œã€åŒä¸€é…ä¿¡å†…ã§ã¯æ­Œå”±é †ã«ä¸¦ã¶
    df_merged = df_merged.sort_values(
        by=["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable", "LIVE_ID", "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—_ç§’"],
        ascending=[False, True, True],
    ).reset_index(drop=True)

    # ===== YouTubeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURLç”Ÿæˆ =====
    # é…ä¿¡URLã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ&t=ç§’æ•°sï¼‰ã‚’ä»˜åŠ 
    # ã“ã‚Œã«ã‚ˆã‚Šã€ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨è©²å½“ã®æ­Œå”±ç®‡æ‰€ã‹ã‚‰å†ç”ŸãŒé–‹å§‹ã•ã‚Œã‚‹
    df_merged["YouTubeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURL"] = df_merged.apply(
        lambda row: (
            f"{row['å…ƒãƒ©ã‚¤ãƒ–URL']}&t={int(row['ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—_ç§’'])}s"
            if pd.notna(row["å…ƒãƒ©ã‚¤ãƒ–URL"]) and pd.notna(row["ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—_ç§’"])
            else ""
        ),
        axis=1,
    )

    # ===== æ›²ç›®ç•ªå·ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ =====
    # å„é…ä¿¡å†…ã§ã®æ¥½æ›²ã®æ­Œå”±é †åºã‚’ç¤ºã™æ›²ç›®ç•ªå·ã‚’ç”Ÿæˆã™ã‚‹
    # åŒä¸€æ—¥ã«è¤‡æ•°é…ä¿¡ãŒã‚ã‚‹å ´åˆã¯ã€Œé…ä¿¡ç•ªå·-æ›²é †ã€å½¢å¼ã€å˜ä¸€é…ä¿¡ã®å ´åˆã¯ã€Œæ›²é †ã€å½¢å¼ã§è¡¨ç¤º
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: å„é…ä¿¡å†…ã§ã®æ›²é †ã‚’è¨ˆç®—
    # groupby("LIVE_ID").cumcount()ã«ã‚ˆã‚Šã€å„é…ä¿¡å†…ã§0ã‹ã‚‰å§‹ã¾ã‚‹é€£ç•ªã‚’ç”Ÿæˆã—ã€+1ã§1å§‹ã¾ã‚Šã«ã™ã‚‹
    df_merged["æ›²é †"] = df_merged.groupby("LIVE_ID").cumcount() + 1

    # ã‚¹ãƒ†ãƒƒãƒ—2: åŒä¸€æ—¥å†…ã®é…ä¿¡ã«ç•ªå·ã‚’æŒ¯ã‚‹ï¼ˆãƒ©ã‚¤ãƒ–ç•ªå·ï¼‰
    def assign_live_number_per_date(group_df):
        """
        åŒä¸€æ—¥ä»˜å†…ã®å„é…ä¿¡ã«é€£ç•ªï¼ˆãƒ©ã‚¤ãƒ–ç•ªå·ï¼‰ã‚’æŒ¯ã‚‹
        
        Args:
            group_df: åŒä¸€æ—¥ä»˜ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚ŒãŸDataFrame
        
        Returns:
            DataFrame: LIVE_IDã¨ãƒ©ã‚¤ãƒ–ç•ªå·ã‚’å«ã‚€DataFrame
        """
        # factorizeã«ã‚ˆã‚Šã€LIVE_IDã®å‡ºç¾é †ã«0ã‹ã‚‰å§‹ã¾ã‚‹ç•ªå·ã‚’æŒ¯ã‚Šã€+1ã§1å§‹ã¾ã‚Šã«ã™ã‚‹
        factor_codes, _ = pd.factorize(group_df["LIVE_ID"])
        group_df["ãƒ©ã‚¤ãƒ–ç•ªå·"] = factor_codes + 1
        return group_df[["LIVE_ID", "ãƒ©ã‚¤ãƒ–ç•ªå·"]]

    # ãƒ©ã‚¤ãƒ–ç•ªå·ã®è¨ˆç®—: æ—¥ä»˜ã¨LIVE_IDã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªçµ„ã¿åˆã‚ã›ã‚’æŠ½å‡º
    temp_live_numbers = (
        df_merged[["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable", "LIVE_ID"]].drop_duplicates().copy()
    )

    # ã‚½ãƒ¼ãƒˆã—ã¦ã€factorizeã®é †åºã‚’å®‰å®šã•ã›ã‚‹ï¼ˆLIVE_IDã®æ˜‡é †ï¼‰
    temp_live_numbers = temp_live_numbers.sort_values(
        by=["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable", "LIVE_ID"]
    )

    # æ—¥ä»˜ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€å„é…ä¿¡ã«ãƒ©ã‚¤ãƒ–ç•ªå·ã‚’æŒ¯ã‚‹
    temp_live_numbers = temp_live_numbers.groupby(
        "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable", group_keys=False
    ).apply(assign_live_number_per_date, include_groups=False)

    # ã‚¹ãƒ†ãƒƒãƒ—3: å…ƒã®DataFrameã«ãƒ©ã‚¤ãƒ–ç•ªå·ã‚’ãƒãƒ¼ã‚¸
    df_merged = pd.merge(
        df_merged,
        temp_live_numbers[["LIVE_ID", "ãƒ©ã‚¤ãƒ–ç•ªå·"]],
        on=["LIVE_ID"],
        how="left",
        suffixes=("", "_new"),
    )

    # ãƒãƒ¼ã‚¸ã§é‡è¤‡ã—ãŸåˆ—ãŒã‚ã‚‹å ´åˆã¯æ–°ã—ã„æ–¹ã‚’ä½¿ç”¨
    if "ãƒ©ã‚¤ãƒ–ç•ªå·_new" in df_merged.columns:
        df_merged["ãƒ©ã‚¤ãƒ–ç•ªå·"] = df_merged["ãƒ©ã‚¤ãƒ–ç•ªå·_new"]
        df_merged = df_merged.drop(columns=["ãƒ©ã‚¤ãƒ–ç•ªå·_new"])

    # ã‚¹ãƒ†ãƒƒãƒ—4: å„æ—¥ä»˜ã®é…ä¿¡æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    # åŒä¸€æ—¥ã«è¤‡æ•°é…ä¿¡ãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ãŸã‚
    live_counts_per_date = df_merged.groupby("ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable")[
        "LIVE_ID"
    ].transform("nunique")

    # ã‚¹ãƒ†ãƒƒãƒ—5: æ›²ç›®ç•ªå·ã®è¡¨ç¤ºå½¢å¼ã‚’æ±ºå®š
    # åŒä¸€æ—¥ã«è¤‡æ•°é…ä¿¡ãŒã‚ã‚‹å ´åˆ: "1-3æ›²ç›®"ï¼ˆ1ç•ªç›®ã®é…ä¿¡ã®3æ›²ç›®ï¼‰
    # åŒä¸€æ—¥ã«å˜ä¸€é…ä¿¡ã®å ´åˆ: "3æ›²ç›®"
    df_merged["æ›²ç›®"] = df_merged.apply(
        lambda row: (
            f"{row['ãƒ©ã‚¤ãƒ–ç•ªå·']}-{row['æ›²é †']}æ›²ç›®"
            if live_counts_per_date.loc[row.name] > 1
            else f"{row['æ›²é †']}æ›²ç›®"
        ),
        axis=1,
    )

    st.session_state.df_full = df_merged.copy()

    # ===== æ¤œç´¢æ©Ÿèƒ½ã®å®Ÿè£… =====
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã«ã‚ˆã‚Šã€æ›²åãƒ»ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆãƒ»é…ä¿¡ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æ¥½æ›²ã‚’çµã‚Šè¾¼ã‚€
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ä½¿ç”¨ã—ã¦ã€æ¤œç´¢æ¡ä»¶ã¨çµæœã‚’ä¿æŒã™ã‚‹
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    # Streamlitã¯ãƒšãƒ¼ã‚¸å†èª­ã¿è¾¼ã¿æ™‚ã«å¤‰æ•°ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹ãŸã‚ã€
    # session_stateã‚’ä½¿ç”¨ã—ã¦çŠ¶æ…‹ã‚’æ°¸ç¶šåŒ–ã™ã‚‹
    if "search_query" not in st.session_state:
        st.session_state.search_query = ""  # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    if "filtered_df" not in st.session_state:
        st.session_state.filtered_df = st.session_state.df_full.copy()  # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿
    if "include_live_title" not in st.session_state:
        st.session_state.include_live_title = True  # é…ä¿¡ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ãƒ•ãƒ©ã‚°
    if "display_limit" not in st.session_state:
        st.session_state.display_limit = 25  # åˆæœŸè¡¨ç¤ºä»¶æ•°ï¼ˆæ®µéšçš„è¡¨ç¤ºç”¨ï¼‰
    if "search_query_prev" not in st.session_state:
        st.session_state.search_query_prev = st.session_state.search_query
    if "include_live_title_prev" not in st.session_state:
        st.session_state.include_live_title_prev = st.session_state.include_live_title

    # æ¤œç´¢UIè¦ç´ ã®é…ç½®
    # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒœãƒƒã‚¯ã‚¹: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›ç”¨
    current_input = st.text_input(
        "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆæ›²åã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆï¼‰",
        key="search_input_box",
        placeholder="ã“ã“ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›",
    )

    # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹: é…ä¿¡ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¤œç´¢å¯¾è±¡ã«å«ã‚ã‚‹ã‹ã©ã†ã‹
    current_checkbox_value = st.checkbox(
        "æ¤œç´¢å¯¾è±¡ã«ãƒ©ã‚¤ãƒ–é…ä¿¡ã‚¿ã‚¤ãƒˆãƒ«ã‚’å«ã‚ã‚‹",
        key="include_live_title_checkbox",
    )

    # æ¤œç´¢ãƒœã‚¿ãƒ³
    search_button = st.button("æ¤œç´¢")

    # ===== æ¤œç´¢å‡¦ç†ã®å®Ÿè¡Œ =====
    # æ¤œç´¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸå ´åˆã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ
    if search_button:
        # ç¾åœ¨ã®å…¥åŠ›å€¤ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        st.session_state.search_query = current_input
        st.session_state.include_live_title = current_checkbox_value
        st.session_state.display_limit = 25  # æ¤œç´¢æ¡ä»¶ãŒå¤‰ã‚ã£ãŸã‚‰è¡¨ç¤ºä»¶æ•°ã‚’ãƒªã‚»ãƒƒãƒˆ

        if st.session_state.search_query:
            # ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã®æ§‹ç¯‰: æ›²åã¾ãŸã¯ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã«æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹
            # str.contains()ã§éƒ¨åˆ†ä¸€è‡´æ¤œç´¢ã€case=Falseã§å¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„
            filter_condition = st.session_state.df_full["æ›²å"].astype(
                str
            ).str.contains(
                st.session_state.search_query, case=False, na=False
            ) | st.session_state.df_full[
                "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ"
            ].astype(
                str
            ).str.contains(
                st.session_state.search_query, case=False, na=False
            )

            # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãŒã‚ªãƒ³ã®å ´åˆã€é…ä¿¡ã‚¿ã‚¤ãƒˆãƒ«ã‚‚æ¤œç´¢å¯¾è±¡ã«è¿½åŠ 
            if st.session_state.include_live_title:
                filter_condition = filter_condition | st.session_state.df_full[
                    "ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒˆãƒ«"
                ].astype(str).str.contains(
                    st.session_state.search_query, case=False, na=False
                )

            # ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’é©ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã‚€
            st.session_state.filtered_df = st.session_state.df_full[
                filter_condition
            ].copy()
            st.write(
                f"ã€Œ{st.session_state.search_query}ã€ã§æ¤œç´¢ã—ãŸçµæœ: {len(st.session_state.filtered_df)}ä»¶"
            )
        else:
            # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒç©ºã®å ´åˆã¯å…¨ä»¶è¡¨ç¤º
            st.session_state.filtered_df = st.session_state.df_full.copy()
            st.write("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…¨ä»¶è¡¨ç¤ºã—ã¾ã™ã€‚")
    
    # æ¤œç´¢ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã¦ã„ãªã„å ´åˆã®å‡¦ç†
    # ä»¥å‰ã®æ¤œç´¢çµæœã‚’ç¶­æŒã—ã¦è¡¨ç¤º
    elif st.session_state.search_query:
        # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã€ä»¥å‰ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœã‚’è¡¨ç¤º
        st.write(
            f"ã€Œ{st.session_state.search_query}ã€ã§æ¤œç´¢ã—ãŸçµæœ: {len(st.session_state.filtered_df)}ä»¶"
        )
    else:
        # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒç©ºã®å ´åˆã¯å…¨ä»¶è¡¨ç¤º
        st.session_state.filtered_df = st.session_state.df_full.copy()
        st.write("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…¨ä»¶è¡¨ç¤ºã—ã¾ã™ã€‚")

    # ç¾åœ¨ã®å…¥åŠ›å€¤ã‚’ä¿å­˜ï¼ˆæ¬¡å›ã®å¤‰æ›´æ¤œçŸ¥ç”¨ï¼‰
    st.session_state.search_query_prev = current_input
    st.session_state.include_live_title_prev = current_checkbox_value

    # ===== æ®µéšçš„è¡¨ç¤ºå‡¦ç† =====
    # æ¤œç´¢çµæœã‚’25ä»¶ãšã¤æ®µéšçš„ã«è¡¨ç¤ºã™ã‚‹ã“ã¨ã§ã€
    # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚åˆæœŸè¡¨ç¤ºé€Ÿåº¦ã‚’ç¶­æŒã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’å‘ä¸Šã•ã›ã‚‹
    df_to_show = st.session_state.filtered_df.copy()

    # YouTubeãƒªãƒ³ã‚¯ã‚’HTMLå½¢å¼ã«å¤‰æ›
    # target="_blank"ã«ã‚ˆã‚Šã€æ–°ã—ã„ã‚¿ãƒ–ã§å‹•ç”»ã‚’é–‹ã
    df_to_show["YouTubeãƒªãƒ³ã‚¯"] = df_to_show.apply(
        lambda row: f'<a href="{row["YouTubeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURL"]}" target="_blank">YouTubeã¸ğŸ‘»</a>',
        axis=1,
    )

    # è¡¨ç¤ºã«ä¸è¦ãªå†…éƒ¨å‡¦ç†ç”¨ã®åˆ—ã‚’å‰Šé™¤
    # ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¦‹ã›ã‚‹æƒ…å ±ã‚’æ•´ç†ã™ã‚‹
    df_to_show = df_to_show.drop(
        columns=[
            "YouTubeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURL",  # HTMLãƒªãƒ³ã‚¯ç”Ÿæˆå¾Œã¯ä¸è¦
            "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_original",          # å…ƒã®é…ä¿¡æ—¥ãƒ‡ãƒ¼ã‚¿ï¼ˆå†…éƒ¨å‡¦ç†ç”¨ï¼‰
            "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable",          # ã‚½ãƒ¼ãƒˆç”¨ã®æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿
            "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—_ç§’",              # ç§’æ•°å¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿ï¼ˆURLç”Ÿæˆã«ä½¿ç”¨æ¸ˆã¿ï¼‰
            "LIVE_ID",                       # å†…éƒ¨ID
            "æ¥½æ›²ID",                        # å†…éƒ¨ID
            "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—",                # å…ƒã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ–‡å­—åˆ—
            "ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒˆãƒ«",                # æ¤œç´¢ã«ã¯ä½¿ç”¨ã—ãŸãŒè¡¨ç¤ºã¯ä¸è¦
            "å…ƒãƒ©ã‚¤ãƒ–URL",                   # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURLç”Ÿæˆã«ä½¿ç”¨æ¸ˆã¿
        ],
        errors="ignore",  # åˆ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã‚‚ã‚¨ãƒ©ãƒ¼ã‚’å‡ºã•ãªã„
    )

    # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåˆ—ã«ã‚«ã‚¹ã‚¿ãƒ CSSã‚¯ãƒ©ã‚¹ã‚’é©ç”¨
    # style.cssã®.artist-cellã‚¯ãƒ©ã‚¹ã«ã‚ˆã‚Šã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã®ã¿æ”¹è¡Œã‚’è¨±å¯
    # é•·ã„ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåã§ã‚‚ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãŒå´©ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹
    df_to_show["ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ"] = (
        df_to_show["ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ"]
        .astype(str)
        .apply(lambda x: f'<div class="artist-cell">{x}</div>')
    )

    # è¡¨ç¤ºã™ã‚‹åˆ—ã®é †åºã‚’å®šç¾©
    final_display_columns = [
        "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥",
        "æ›²ç›®",
        "æ›²å",
        "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ",
        "YouTubeãƒªãƒ³ã‚¯",
    ]
    # DataFrameã«å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’é¸æŠï¼ˆå®‰å…¨æ€§ã®ãŸã‚ï¼‰
    final_display_columns = [
        col for col in final_display_columns if col in df_to_show.columns
    ]

    # è¡¨ç¤ºä»¶æ•°ã‚’åˆ¶é™ï¼ˆæ®µéšçš„è¡¨ç¤ºï¼‰
    # display_limitã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ç®¡ç†ã•ã‚Œã€ã€Œã•ã‚‰ã«è¡¨ç¤ºã€ãƒœã‚¿ãƒ³ã§å¢—åŠ ã™ã‚‹
    df_limited_display = df_to_show[final_display_columns].head(
        st.session_state.display_limit
    )

    # DataFrameã‚’HTMLãƒ†ãƒ¼ãƒ–ãƒ«ã«å¤‰æ›
    # escape=False: HTMLã‚¿ã‚°ã‚’ãã®ã¾ã¾è¡¨ç¤ºï¼ˆãƒªãƒ³ã‚¯ã¨CSSã‚¯ãƒ©ã‚¹ã‚’æœ‰åŠ¹åŒ–ï¼‰
    # index=False: è¡Œç•ªå·ã‚’éè¡¨ç¤º
    html_table = df_limited_display.to_html(
        escape=False, index=False, justify="left", classes="dataframe"
    )

    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’çŸ­ç¸®å½¢ã«ç½®ãæ›ãˆ
    # ã‚ˆã‚Šè¦‹ã‚„ã™ãã€ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªè¡¨ç¤ºã«ã™ã‚‹
    custom_headers = {
        "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥": "é…ä¿¡æ—¥",
        "æ›²ç›®": "No.",
        "æ›²å": "æ›²å",
        "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ": "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ",
        "YouTubeãƒªãƒ³ã‚¯": "ãƒªãƒ³ã‚¯",
    }
    for original, custom in custom_headers.items():
        html_table = html_table.replace(f"<th>{original}</th>", f"<th>{custom}</th>")

    # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªdivã§å›²ã‚€
    # æ¨ªå¹…ãŒåºƒã„å ´åˆã§ã‚‚æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã§å¯¾å¿œã—ã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãŒå´©ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹
    scrollable_html = f"""
    <div style="overflow-x: auto; max-width: 100%;">
        {html_table}
    </div>
    """
    # ç”Ÿæˆã—ãŸHTMLã‚’Streamlitã§è¡¨ç¤º
    st.write(scrollable_html, unsafe_allow_html=True)

    # ===== ã€Œã•ã‚‰ã«è¡¨ç¤ºã€ãƒœã‚¿ãƒ³ =====
    # è¡¨ç¤ºä»¶æ•°ãŒæ¤œç´¢çµæœã®ç·ä»¶æ•°ã‚ˆã‚Šå°‘ãªã„å ´åˆã«ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    if st.session_state.display_limit < len(st.session_state.filtered_df):
        if st.button(
            f"ã•ã‚‰ã«25ä»¶è¡¨ç¤ºï¼ˆç¾åœ¨ã®è¡¨ç¤º: {min(st.session_state.display_limit, len(st.session_state.filtered_df))}/{len(st.session_state.filtered_df)}ä»¶ï¼‰"
        ):
            # ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã‚‰è¡¨ç¤ºä»¶æ•°ã‚’25ä»¶å¢—ã‚„ã™
            st.session_state.display_limit += 25
            st.rerun()  # ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦æ›´æ–°ã‚’åæ˜ 
    else:
        # å…¨ä»¶è¡¨ç¤ºæ¸ˆã¿ã®å ´åˆã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        st.info(f"å…¨ã¦ã®{len(st.session_state.filtered_df)}ä»¶ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚")

else:
    st.warning(
        "å¿…è¦ãªTSVãƒ•ã‚¡ã‚¤ãƒ«ãŒã™ã¹ã¦èª­ã¿è¾¼ã‚ãªã‹ã£ãŸãŸã‚ã€çµåˆãƒ‡ãƒ¼ã‚¿ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚"
    )

# ãƒ•ãƒƒã‚¿ãƒ¼ã®è¡¨ç¤º
display_footer()  # â˜…ã“ã“ã‚’å‘¼ã³å‡ºã™â˜…
