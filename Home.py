import streamlit as st
import pandas as pd
from PIL import Image

# ãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚¿ãƒ–åã‚’ã€Œã—ã®ã†ãŸã‚¿ã‚¤ãƒ ã€ã«è¨­å®šã—ã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’åºƒã‚ã«è¨­å®š
st.set_page_config(
    page_title="ã—ã®ã†ãŸã‚¿ã‚¤ãƒ ",
    page_icon="ğŸ‘»",
    layout="wide",
)

# --- ã‚«ã‚¹ã‚¿ãƒ CSSã®é©ç”¨ ---
try:
    with open("style.css", encoding="utf-8") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
except FileNotFoundError:
    st.error("ã‚¨ãƒ©ãƒ¼: style.css ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.info("`style.css` ãŒã‚¢ãƒ—ãƒªã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
except Exception as e:
    st.error(f"ã‚¨ãƒ©ãƒ¼: style.css ã®èª­ã¿è¾¼ã¿ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
# --- ã‚«ã‚¹ã‚¿ãƒ CSSã®é©ç”¨ã“ã“ã¾ã§ ---

st.title("ã—ã®ã†ãŸã‚¿ã‚¤ãƒ ğŸ‘»ğŸ«§")

# --- æ¦‚è¦æ¬„ã®è¿½åŠ  ---
st.markdown(
    """
    ã“ã¡ã‚‰ã¯VTuberã€Œ[å¹½éŸ³ã—ã®](https://www.774.ai/talent/shino-kasukane)ã€ã•ã‚“ã®é…ä¿¡ã§æ­Œã‚ã‚ŒãŸæ¥½æ›²ã‚’ã¾ã¨ã‚ãŸéå…¬å¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã™ã€‚
    æ›²åã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã€ãƒ©ã‚¤ãƒ–é…ä¿¡ã‚¿ã‚¤ãƒˆãƒ«ã§æ¤œç´¢ã§ãã¾ã™ã€‚YouTubeãƒªãƒ³ã‚¯ã‹ã‚‰è©²å½“ã®æ­Œå”±ç®‡æ‰€ã«ç›´æ¥é£›ã¹ã¾ã™ã€‚
    """
)
st.markdown("---")
# --- æ¦‚è¦æ¬„ã®è¿½åŠ ã“ã“ã¾ã§ ---

# --- TSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ ---
lives_file_path = "data/M_YT_LIVE.TSV"
songs_file_path = "data/M_YT_LIVE_TIMESTAMP.TSV"


# --- æ™‚é–“æ–‡å­—åˆ—ã‚’ç§’æ•°ã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def convert_timestamp_to_seconds(timestamp_str):
    if pd.isna(timestamp_str) or not isinstance(timestamp_str, str):
        return None

    parts = list(map(int, timestamp_str.split(":")))

    if len(parts) == 3:
        return parts[0] * 3600 + parts[1] * 60 + parts[2]
    elif len(parts) == 2:
        return parts[0] * 60 + parts[1]
    else:
        return None


# --- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
df_lives = None
df_songs = None

try:
    df_lives = pd.read_csv(lives_file_path, delimiter="\t")
except FileNotFoundError:
    st.error(f'ã‚¨ãƒ©ãƒ¼: é…ä¿¡æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ« "{lives_file_path}" ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚')
    st.info(f"`{lives_file_path}` ãŒã‚¢ãƒ—ãƒªã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
except Exception as e:
    st.error(
        f'é…ä¿¡æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ« "{lives_file_path}" ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}'
    )

try:
    df_songs = pd.read_csv(songs_file_path, delimiter="\t")
except FileNotFoundError:
    st.error(f'ã‚¨ãƒ©ãƒ¼: æ¥½æ›²æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ« "{songs_file_path}" ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚')
    st.info(f"`{songs_file_path}` ãŒã‚¢ãƒ—ãƒªã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
except Exception as e:
    st.error(
        f'æ¥½æ›²æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ« "{songs_file_path}" ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}'
    )


# --- ãƒ‡ãƒ¼ã‚¿ã®çµåˆã¨è¡¨ç¤º ---
if df_lives is not None and df_songs is not None:
    # 'ID' (M_YT_LIVE.TSV) ã¨ 'LIVE_ID' (M_YT_LIVE_TIMESTAMP.TSV) ã‚’ã‚­ãƒ¼ã¨ã—ã¦çµåˆ
    df_merged = pd.merge(
        df_songs,
        df_lives[["ID", "é…ä¿¡æ—¥", "ã‚¿ã‚¤ãƒˆãƒ«", "URL"]],
        left_on="LIVE_ID",
        right_on="ID",
        how="left",
        suffixes=("_song", "_live"),
    )

    # çµåˆã«ä½¿ã£ãŸãŒã€é‡è¤‡ã™ã‚‹M_YT_LIVE.TSVå´ã®IDåˆ—ï¼ˆ`ID_live`ï¼‰ã‚’å‰Šé™¤
    df_merged = df_merged.drop(columns=["ID_live"])

    # åˆ—åã‚’åˆ†ã‹ã‚Šã‚„ã™ãå¤‰æ›´
    df_merged = df_merged.rename(
        columns={
            "ID_song": "æ¥½æ›²ID",
            "é…ä¿¡æ—¥": "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_original",
            "ã‚¿ã‚¤ãƒˆãƒ«": "ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒˆãƒ«",
            "URL": "å…ƒãƒ©ã‚¤ãƒ–URL",
        }
    )
    # è¡¨ç¤ºç”¨ã®ã€Œãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥ã€ã¯ã€å…ƒã®ã€Œãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_originalã€ã‚’ãã®ã¾ã¾ä½¿ã†
    df_merged["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥"] = df_merged["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_original"]

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç§’æ•°ã«å¤‰æ›ã™ã‚‹æ–°ã—ã„åˆ—ã‚’è¿½åŠ 
    df_merged["ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—_ç§’"] = df_merged["ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—"].apply(
        convert_timestamp_to_seconds
    )

    # --- æ–°ã—ã„æ›²ç›®ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®é–‹å§‹ ---
    # ã‚½ãƒ¼ãƒˆç”¨ã«æ—¥ä»˜å‹ã«å¤‰æ›ã—ãŸã‚«ãƒ©ãƒ ã‚’ä½œæˆ
    df_merged["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable"] = pd.to_datetime(
        df_merged["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_original"], unit="ms", errors="coerce"
    )

    # UNIXãƒŸãƒªç§’ã§å¤‰æ›ã§ããªã‹ã£ãŸï¼ˆNaTã®ï¼‰è¡Œã«å¯¾ã—ã¦ã€YYYY/MM/DDå½¢å¼ã¨ã—ã¦å†å¤‰æ›ã‚’è©¦ã¿ã‚‹
    mask_nat_sortable = df_merged["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable"].isna()
    if mask_nat_sortable.any():
        try:
            df_merged.loc[mask_nat_sortable, "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable"] = pd.to_datetime(
                df_merged.loc[mask_nat_sortable, "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_original"],
                errors="coerce",
            )
        except Exception as e:
            st.warning(f"ã‚½ãƒ¼ãƒˆç”¨ã®ã€Œãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥ã€å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.warning(
                "æ—¥ä»˜ã®å½¢å¼ãŒè¤‡é›‘ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚TSVãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ã€Œé…ä¿¡æ—¥ã€ã‚«ãƒ©ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            )

    # ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥ã®é™é † (æ–°ã—ã„æ—¥ä»˜ãŒä¸Š)ã€ã‹ã¤ãã®ä¸­ã§ LIVE_ID ã®æ˜‡é †ã€ã•ã‚‰ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ˜‡é †ã§ã‚½ãƒ¼ãƒˆ
    df_merged = df_merged.sort_values(
        by=["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable", "LIVE_ID", "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—_ç§’"],
        ascending=[False, True, True],
    ).reset_index(drop=True)

    # YouTubeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURLã‚’æ­£ã—ãä½œæˆ
    df_merged["YouTubeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURL"] = df_merged.apply(
        lambda row: (
            f"{row['å…ƒãƒ©ã‚¤ãƒ–URL']}&t={int(row['ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—_ç§’'])}s"
            if pd.notna(row["å…ƒãƒ©ã‚¤ãƒ–URL"]) and pd.notna(row["ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—_ç§’"])
            else ""
        ),
        axis=1,
    )

    # åŒã˜æ—¥ä»˜ã®ãƒ©ã‚¤ãƒ–ã«é…ä¿¡ç•ªå·ã‚’æŒ¯ã‚‹
    df_merged["æ—¥ä»˜_LIVE_ID_tuple"] = list(
        zip(df_merged["ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable"], df_merged["LIVE_ID"])
    )
    unique_tuples, live_nums = pd.factorize(df_merged["æ—¥ä»˜_LIVE_ID_tuple"])
    df_merged["ãƒ©ã‚¤ãƒ–ç•ªå·"] = unique_tuples + 1
    df_merged = df_merged.drop(columns=["æ—¥ä»˜_LIVE_ID_tuple"])

    # å„ãƒ©ã‚¤ãƒ–é…ä¿¡å†…ã§æ¥½æ›²ã«é€£ç•ªã‚’æŒ¯ã‚‹
    df_merged["æ›²é †"] = df_merged.groupby("LIVE_ID").cumcount() + 1

    # æ–°ã—ã„æ›²ç›®å½¢å¼ã‚’ç”Ÿæˆ
    live_counts_per_date = df_merged.groupby("ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable")[
        "LIVE_ID"
    ].transform("nunique")

    df_merged["æ›²ç›®"] = df_merged.apply(
        lambda row: (
            f"{row['ãƒ©ã‚¤ãƒ–ç•ªå·']}-{row['æ›²é †']}æ›²ç›®"
            if live_counts_per_date.loc[row.name] > 1
            else f"{row['æ›²é †']}æ›²ç›®"
        ),
        axis=1,
    )
    # --- æ–°ã—ã„æ›²ç›®ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®çµ‚äº† ---

    st.session_state.df_full = df_merged.copy()

    # --- æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹ã¨ãƒœã‚¿ãƒ³ã€ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®è¿½åŠ  ---
    if "search_query" not in st.session_state:
        st.session_state.search_query = ""
    if "filtered_df" not in st.session_state:
        st.session_state.filtered_df = st.session_state.df_full.copy()
    if "include_live_title" not in st.session_state:
        st.session_state.include_live_title = True
    if "display_limit" not in st.session_state:
        st.session_state.display_limit = 25  # åˆæœŸè¡¨ç¤ºä»¶æ•°

    current_input = st.text_input(
        "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆæ›²åã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆï¼‰",
        value=st.session_state.search_query,
        key="search_input_box",
        placeholder="ã“ã“ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›",
    )

    current_checkbox_value = st.checkbox(
        "æ¤œç´¢å¯¾è±¡ã«ãƒ©ã‚¤ãƒ–é…ä¿¡ã‚¿ã‚¤ãƒˆãƒ«ã‚’å«ã‚ã‚‹",
        value=st.session_state.include_live_title,
        key="include_live_title_checkbox",
    )

    search_button = st.button("æ¤œç´¢")

    if search_button:
        st.session_state.search_query = current_input
        st.session_state.include_live_title = current_checkbox_value
        st.session_state.display_limit = 25

        if st.session_state.search_query:
            filter_condition = st.session_state.df_full["æ›²å"].astype(
                str
            ).str.contains(
                st.session_state.search_query, case=False, na=False
            ) | st.session_state.df_full[
                "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ"
            ].astype(
                str
            ).str.contains(
                st.session_state.search_query, case=False, na=False
            )

            if st.session_state.include_live_title:
                filter_condition = filter_condition | st.session_state.df_full[
                    "ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒˆãƒ«"
                ].astype(str).str.contains(
                    st.session_state.search_query, case=False, na=False
                )

            st.session_state.filtered_df = st.session_state.df_full[
                filter_condition
            ].copy()
            st.write(
                f"ã€Œ{st.session_state.search_query}ã€ã§æ¤œç´¢ã—ãŸçµæœ: {len(st.session_state.filtered_df)}ä»¶"
            )
        else:
            st.session_state.filtered_df = st.session_state.df_full.copy()
            st.write("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…¨ä»¶è¡¨ç¤ºã—ã¾ã™ã€‚")
    elif not st.session_state.search_query and not search_button:
        st.session_state.filtered_df = st.session_state.df_full.copy()
        st.write("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…¨ä»¶è¡¨ç¤ºã—ã¾ã™ã€‚")

    # ã“ã“ã‹ã‚‰æ®µéšçš„è¡¨ç¤ºã®å‡¦ç†
    df_to_show = st.session_state.filtered_df.copy()

    # YouTubeãƒªãƒ³ã‚¯ã‚’HTMLå½¢å¼ã§ç›´æ¥åŸ‹ã‚è¾¼ã‚€ãŸã‚ã«å¤‰æ›
    df_to_show["YouTubeãƒªãƒ³ã‚¯"] = df_to_show.apply(
        lambda row: f'<a href="{row["YouTubeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURL"]}" target="_blank">YouTubeã¸ğŸ‘»</a>',
        axis=1,
    )

    # --- ä¸è¦ãªåˆ—ã‚’å‰Šé™¤ ---
    df_to_show = df_to_show.drop(
        columns=[
            "YouTubeã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURL",  # HTMLãƒªãƒ³ã‚¯ç”Ÿæˆå¾Œã«å‰Šé™¤
            "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_original",
            "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥_sortable",
            "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—_ç§’",
            "LIVE_ID",
            "æ¥½æ›²ID",
            "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—",
            "ãƒ©ã‚¤ãƒ–ç•ªå·",
            "æ›²é †",
            "ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒˆãƒ«",  # â˜…å‰Šé™¤å¯¾è±¡
            "å…ƒãƒ©ã‚¤ãƒ–URL",  # â˜…å‰Šé™¤å¯¾è±¡
        ],
        errors="ignore",
    )

    # ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆåˆ—ã«ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹ã‚’é©ç”¨ (style.cssã« .artist-cell ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚Œã°æ©Ÿèƒ½ã—ã¾ã™)
    df_to_show["ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ"] = (
        df_to_show["ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ"]
        .astype(str)
        .apply(lambda x: f'<div class="artist-cell">{x}</div>')
    )

    # è¡¨ç¤ºã™ã‚‹åˆ—ã®é †åºã‚’å†èª¿æ•´
    final_display_columns = [
        "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥",
        "æ›²ç›®",
        "æ›²å",
        "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ",
        "YouTubeãƒªãƒ³ã‚¯",
        # "ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒˆãƒ«", # â˜…å‰Šé™¤å¯¾è±¡
        # "å…ƒãƒ©ã‚¤ãƒ–URL",    # â˜…å‰Šé™¤å¯¾è±¡
    ]
    # å®Ÿéš›ã«DataFrameã«å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’é¸æŠã—ã¦è¡¨ç¤º
    final_display_columns = [
        col for col in final_display_columns if col in df_to_show.columns
    ]

    # è¡¨ç¤ºä»¶æ•°ã‚’åˆ¶é™
    df_limited_display = df_to_show[final_display_columns].head(
        st.session_state.display_limit
    )

    # DataFrameã‚’HTMLã¨ã—ã¦ç”Ÿæˆ
    html_table = df_limited_display.to_html(
        escape=False, index=False, justify="left", classes="dataframe"
    )

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã®ç½®ãæ›ãˆè¾æ›¸
    custom_headers = {
        "ãƒ©ã‚¤ãƒ–é…ä¿¡æ—¥": "é…ä¿¡æ—¥",
        "æ›²ç›®": "No.",
        "æ›²å": "æ›²å",
        "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ": "ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ",
        "YouTubeãƒªãƒ³ã‚¯": "ãƒªãƒ³ã‚¯",
        # "ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒˆãƒ«": "ãƒ©ã‚¤ãƒ–ã‚¿ã‚¤ãƒˆãƒ«", # â˜…å‰Šé™¤å¯¾è±¡
        # "å…ƒãƒ©ã‚¤ãƒ–URL": "å…ƒãƒ©ã‚¤ãƒ–URL",    # â˜…å‰Šé™¤å¯¾è±¡
    }

    # HTMLæ–‡å­—åˆ—å†…ã§å„ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ç½®ãæ›ãˆã‚‹
    for original, custom in custom_headers.items():
        html_table = html_table.replace(f"<th>{original}</th>", f"<th>{custom}</th>")

    # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªdivã§å›²ã‚€
    scrollable_html = f"""
    <div style="overflow-x: auto; max-width: 100%;">
        {html_table}
    </div>
    """
    # ç”Ÿæˆã—ãŸHTMLã‚’Streamlitã§è¡¨ç¤º
    st.write(scrollable_html, unsafe_allow_html=True)

    # ã€Œã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³
    if st.session_state.display_limit < len(st.session_state.filtered_df):
        if st.button(
            f"ã•ã‚‰ã«25ä»¶è¡¨ç¤ºï¼ˆç¾åœ¨ã®è¡¨ç¤º: {min(st.session_state.display_limit, len(st.session_state.filtered_df))}/{len(st.session_state.filtered_df)}ä»¶ï¼‰"
        ):
            st.session_state.display_limit += 25
            st.rerun()
    else:
        st.info(f"å…¨ã¦ã®{len(st.session_state.filtered_df)}ä»¶ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚")

else:
    st.warning(
        "å¿…è¦ãªTSVãƒ•ã‚¡ã‚¤ãƒ«ãŒã™ã¹ã¦èª­ã¿è¾¼ã‚ãªã‹ã£ãŸãŸã‚ã€çµåˆãƒ‡ãƒ¼ã‚¿ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚"
    )

st.markdown("---")
st.caption("Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ by Gemini")
st.caption(
    "æœ¬ã‚µã‚¤ãƒˆã«é–¢ã™ã‚‹è³ªå•ãƒ»ãƒã‚°ã®å ±å‘Šãªã©ã¯[@kajuen_kajuen](https://x.com/kajuen_kajuen)ã¾ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚"
)
